[
{"id": "0", "title": "Data Engineer", "company_name": "Công Ty Cổ Phần Công Nghệ VMO Holdings", "salary": "Thoả thuận", "city": "Hà Nội", "yoe": "3 năm", "deadline_submit": "Hạn nộp hồ sơ: 12/01/2025", "main_industry": [], "description": "Gather relevant information on the issue reported.\nTrace where in our pipelines a specific issue comes from.\nProvide initial feedback to the reporter, as appropriate.\nDocument issue, actions taken, timeline and time spent as well as impediments.\nWhere needed summarize findings and raise to core DE team for further action", "requirements": "SQL – necessary\nPython – necessary\nIndependently trace and communicate data issues and solutions – necessary\nFollow SOP or develop new ones as needed\nMake intuitive connections between data inputs and outputs\nBQ - optional, knowledgeable, but preferred.\nHANA studio experience - optional\nPyspark – optional\nCommunication – English written and verbal", "work_address": "- Hà Nội: Tòa IDMC 18 Tôn Thất Thuyết, Cầu Giấy", "company_size": "1000+ nhân viên", "major_field": "IT - Phần mềm", "level": "Nhân viên", "num_of_recruit": "1 người", "work_form": "Toàn thời gian", "gender_require": "Không yêu cầu", "relation_fields": ["Công nghệ Thông tin", "Data Science", "Data Engineer", "Việc làm IT"], "skills": null, "area": ["Hà Nội", "Cầu Giấy"], "update_time": "Cập nhật 20 giờ trước", "remain_time": "Còn 29 ngày để ứng tuyển"},
{"id": "1", "title": "Data Engineer", "company_name": "Công ty Cổ phần Atomi Digital", "salary": "Thoả thuận", "city": "Hà Nội", "yoe": "5 năm", "deadline_submit": "Hạn nộp hồ sơ: 12/01/2025", "main_industry": [], "description": "– Làm việc với BA để chuyển đổi các yêu cầu kinh doanh thành các giải pháp công nghệ\n– Phát triển các hệ thống Hadoop\n– Tiến hành tiền xử lý dữ liệu sử dụng Hive hoặc Pig\n– Đưa ra scopee của hệ thống và giải pháp Big Data tương ứng\n– Xây dựng các cloud patforms cho các ứng dụng của công ty\n– Maintaining các hệ thống product của công ty", "requirements": "– Có hiểu biết về các công nghệ và giải pháp của Big Data\n– Có khả năng lập trình với ít nhất 1 trong các ngôn ngữ bao gồm: Java, Python, C++, Ruby, R\n– Có hiểu biết về NoSQL và RDBMS databases bao gồm Redis và MongoDB\n– Có hiểu biết về BigQuery, Cloud Data Fusion, Dataproc, Dataflow, Data Catalog\n– Quen thuộc với các công cụ của Mesos, AWS, Google Cloud Platform, và Docker", "work_address": "- Hà Nội: 17 Tông Đản, Hoàn Kiếm", "company_size": "100-499 nhân viên", "major_field": "IT - Phần mềm", "level": "Nhân viên", "num_of_recruit": "1 người", "work_form": "Toàn thời gian", "gender_require": "Không yêu cầu", "relation_fields": ["Công nghệ Thông tin", "Data Science", "Data Engineer", "Việc làm IT"], "skills": ["SQL", "Python Hoặc Java", "Cloud Computing (aws, Azure, Gcp)", "Big Data (hadoop, Spark, Hive)", "Etl Processes"], "area": ["Hà Nội", "Hoàn Kiếm"], "update_time": "Cập nhật 1 ngày trước", "remain_time": "Còn 29 ngày để ứng tuyển"},
{"id": "2", "title": "Data Engineer", "company_name": "Crossian", "salary": "Thoả thuận", "city": "Hà Nội", "yoe": "3 năm", "deadline_submit": "Hạn nộp hồ sơ: 05/02/2025", "main_industry": [], "description": "Participate in Requirements Analysis & Technical Specification in the Agile/Scrum development process.\nDesign, develop, and maintain scalable data pipelines and ETL processes to collect, clean, and process large datasets. The system is built on the microservice architecture and deployed Kubernetes (use AWS EKS service) across 3 AWS regions globally (US, HK, SG).\nCollaborate with data scientists, analysts, and other stakeholders to understand data requirements and develop data solutions that meet business needs. Use BI tools for data analytics, such as Grafana, AWS QuickSight, or Excel (Google Sheets).\nDevelop and implement data integration strategies and data transformation logic, ensuring high-quality and accurate data in the data warehouse. Use Kafka and Nifi tech-stack & eco-system to build data flow.\nOptimize and improve the performance, efficiency, and reliability of data pipelines, data models, and data storage solutions. Use database or object storage services like PostgreSQL, Elasticsearch, Redis, and AWS S3.\nMonitor and troubleshoot data pipeline issues, ensuring data integrity and timely data delivery. Use tools for monitoring logs and issues such as Sentry, Grafana, or alerts Slack.\nContinuously evaluate and implement new technologies, tools, and techniques to enhance data engineering capabilities.\nDocument data engineering processes and maintain data dictionaries, ensuring compliance with data governance policies and regulatory requirements. Use the Atlassian toolset (Jira, Confluence) or Slack to help teams organize, collaborate, and complete work together.", "requirements": "Bachelor's degree in Computer Science or a related field.\n3+ years of experience in Backend development or Data engineering, ETL development, or a similar role.\nExperience working with microservice architecture.\nProficiency one of langue in C#, Java, or Python for data processing and scripting.\nExperience working with relational databases, such as one of the database types: PostgreSQL, MySQL, Oracle, or MS SQL Server.\nKnowledge of working with document databases, such as one the database types: Elasticsearch, Redis, MongoDB, or Apache Solr.\nFamiliarity with data warehousing concepts and cloud-based data storage solutions (e.g., AWS, GCP, Azure).\nStrong problem-solving skills, attention to detail, and the ability to work independently and as part of a team.\nExcellent communication and collaboration skills, especially in Agile culture environment.\nPreferred (but not required)\nExperience with container orchestration, such as AWS EKS or Kubernetes\nExperience with data visualization tools, such as AWS QuickSight or Grafana.\nExperience with databases, and object storage services, such as PostgreSQL, Elasticsearch, Redis, and AWS S3.\nExperience with data streaming platforms, such as Apache Kafka or Apache Nifi.\nKnowledge of data integrated from various sources, such as web services, APIs, and file systems.\nFamiliarity with the Agile toolset, such as Gitlab, Jira, Confluence, and Slack.\nEnglish proficiency", "work_address": "- Hà Nội: Tầng 5, Pax Sky, 63-65 Ngô Thì Nhậm, Hai Bà Trưng", "company_size": "100-499 nhân viên", "major_field": "Thương mại điện tử", "level": "Nhân viên", "num_of_recruit": "2 người", "work_form": "Toàn thời gian", "gender_require": "Không yêu cầu", "relation_fields": ["Công nghệ Thông tin", "Data Science", "Data Engineer", "Việc làm IT"], "skills": ["C#", "SQL", "Python Hoặc Java", "Big Data (hadoop, Spark, Hive)", "Data Modeling", "Etl (extract, Transform, Load)", "AWS", "Cloud Computing (aws, Azure, Gcp)"], "area": ["Hà Nội", "Hai Bà Trưng"], "update_time": "Cập nhật 2 ngày trước", "remain_time": "Còn 53 ngày để ứng tuyển"}
]